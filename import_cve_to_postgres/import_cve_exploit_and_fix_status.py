import os
import json
import psycopg2
from psycopg2.extras import execute_values
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

def get_connection():
    return psycopg2.connect(
        host="localhost",
        port="5432",
        dbname="mydatabase",
        user="myuser",
        password="mypassword"
    )

def create_tables(conn):
    with conn.cursor() as cur:
        cur.execute('''
            CREATE TABLE IF NOT EXISTS cve_exploit_status (
                id SERIAL PRIMARY KEY,
                cve_id TEXT NOT NULL UNIQUE,
                has_active_exploit BOOLEAN,
                FOREIGN KEY (cve_id) REFERENCES cve_simple(cve_id) ON DELETE CASCADE
            )
        ''')
        cur.execute('''
            CREATE TABLE IF NOT EXISTS cve_fix_status (
                id SERIAL PRIMARY KEY,
                cve_id TEXT NOT NULL UNIQUE,
                has_fix BOOLEAN,
                FOREIGN KEY (cve_id) REFERENCES cve_simple(cve_id) ON DELETE CASCADE
            )
        ''')
        conn.commit()

def extract_status(json_data):
    cve_id = json_data.get('cveMetadata', {}).get('cveId')
    has_exploit = False
    has_fix = False
    containers = json_data.get('containers', {})
    for container_key in ['cna', 'adp']:
        container = containers.get(container_key)
        if not container:
            continue
        # If container is a list, iterate over its items
        if isinstance(container, list):
            container_list = container
        else:
            container_list = [container]
        for cont in container_list:
            references = cont.get('references', [])
            for ref in references:
                tags = ref.get('tags', [])
                # Exploit detection
                if any('exploit' in tag.lower() for tag in tags):
                    has_exploit = True
                # Fix detection
                if any(tag.lower() in ['vendor-advisory', 'patch', 'fix', 'mitigation', 'update'] for tag in tags):
                    has_fix = True
    return cve_id, has_exploit, has_fix

def process_all_files(base_path, conn):
    exploit_rows = []
    fix_rows = []
    # Fetch all valid cve_ids from cve_simple
    with conn.cursor() as cur:
        cur.execute('SELECT cve_id FROM cve_simple')
        valid_cve_ids = set(row[0] for row in cur.fetchall())
    for root, dirs, files in os.walk(base_path):
        for file in files:
            if file.endswith('.json'):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, encoding='utf-8') as f:
                        data = json.load(f)
                        # Skip files where the top-level JSON is a list
                        if isinstance(data, list):
                            continue
                        cve_id, has_exploit, has_fix = extract_status(data)
                        if cve_id and cve_id in valid_cve_ids:
                            exploit_rows.append((cve_id, has_exploit))
                            fix_rows.append((cve_id, has_fix))
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
    if exploit_rows:
        with conn.cursor() as cur:
            execute_values(cur, """
                INSERT INTO cve_exploit_status (cve_id, has_active_exploit)
                VALUES %s
                ON CONFLICT (cve_id) DO UPDATE SET has_active_exploit = EXCLUDED.has_active_exploit
            """, exploit_rows)
    if fix_rows:
        with conn.cursor() as cur:
            execute_values(cur, """
                INSERT INTO cve_fix_status (cve_id, has_fix)
                VALUES %s
                ON CONFLICT (cve_id) DO UPDATE SET has_fix = EXCLUDED.has_fix
            """, fix_rows)
    conn.commit()

if __name__ == "__main__":
    cve_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'cves')
    conn = get_connection()
    create_tables(conn)
    process_all_files(cve_dir, conn)
    conn.close()
    print("Exploit and fix status import complete.")
